{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwjxUxLUQALN"
      },
      "source": [
        "# Stock Price Forecasting using ARIMA model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pizof5KVJCx5"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "mHoOyqXl6cNC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.stattools import kpss\n",
        "from scipy.stats import normaltest\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CE4ohEaWJKo-"
      },
      "source": [
        "# Importing Data Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "a-m6KvF7HdkI"
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_csv(\"./data/SPX_Real.csv\", index_col=False)\n",
        "df1.columns = ['Timestamp', 'Close']\n",
        "df1.set_index(\"Timestamp\", inplace=True)\n",
        "df1.index = pd.to_datetime(df1.index, format='%d-%m-%Y')\n",
        "df2 = pd.read_csv(\"./data/AAPL_Real.csv\")\n",
        "df2.columns = ['Timestamp', 'Close']\n",
        "df2.set_index(\"Timestamp\", inplace=True)\n",
        "df2.index = pd.to_datetime(df2.index, format='%d-%m-%Y')\n",
        "df3 = pd.read_csv(\"./data/TWSE_Real.csv\")\n",
        "df3.columns = ['Timestamp', 'Close']\n",
        "df3.set_index(\"Timestamp\", inplace=True)\n",
        "df3.index = pd.to_datetime(df3.index, format='%m/%d/%Y')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPZ09pR4r5Js"
      },
      "source": [
        "# Formatting Data Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqFbz3dgRyL-"
      },
      "source": [
        "## Setting Date as the index of the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IlKkT956PItu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of               Close\n",
              "Timestamp          \n",
              "1990-01-03   358.76\n",
              "1990-01-04   355.67\n",
              "1990-01-05   352.20\n",
              "1990-01-08   353.79\n",
              "1990-01-09   349.62\n",
              "...             ...\n",
              "2025-01-17  5996.66\n",
              "2025-01-21  6049.24\n",
              "2025-01-22  6086.37\n",
              "2025-01-23  6118.71\n",
              "2025-01-24  6101.24\n",
              "\n",
              "[8831 rows x 1 columns]>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMH-SyucRpPX"
      },
      "source": [
        "## Merging 3 datasets into 1 DataFrame for simplicity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-nVRxpgJPam"
      },
      "outputs": [],
      "source": [
        "# df = pd.DataFrame({\n",
        "#     \"SPX\": df1.Close,\n",
        "#     \"AAPL\": df2.Close,\n",
        "#     \"AAPL2\": df3.Close\n",
        "# }, index=df1.index) \n",
        "# symbols=['SPX','AAPL','AAPL2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "HzWm8ovAOJTJ",
        "outputId": "6a81b4c3-ea22-45af-ac42-bd3f341c3e74"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SPX</th>\n",
              "      <th>AAPL</th>\n",
              "      <th>AAPL2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>358.76</td>\n",
              "      <td>0.335</td>\n",
              "      <td>0.335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>355.67</td>\n",
              "      <td>0.336</td>\n",
              "      <td>0.336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>352.20</td>\n",
              "      <td>0.337</td>\n",
              "      <td>0.337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>353.79</td>\n",
              "      <td>0.339</td>\n",
              "      <td>0.339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>349.62</td>\n",
              "      <td>0.336</td>\n",
              "      <td>0.336</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      SPX   AAPL  AAPL2\n",
              "0  358.76  0.335  0.335\n",
              "1  355.67  0.336  0.336\n",
              "2  352.20  0.337  0.337\n",
              "3  353.79  0.339  0.339\n",
              "4  349.62  0.336  0.336"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ET7cthDsGQW"
      },
      "source": [
        "# Initial Plotting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHRFPVHFpFR7"
      },
      "source": [
        "## ADF test\n",
        "Augmented Dickey Fuller(ADF) test is a common statistical test used to test whether a given Time series is stationary or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3C_MijraDqt",
        "outputId": "2d8e4f86-e1bb-48f4-d6b6-8aca822d6c47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['SPX']\n",
            "ADF Statistic: 3.429196\n",
            "p-value: 1.000000\n",
            "Critical Values:\n",
            "\t1%: -3.431\n",
            "\t5%: -2.862\n",
            "\t10%: -2.567\n",
            "Failed to reject Null Hypothesis. So, Time Series is Not-Stationary\n",
            "\n",
            "\n",
            "['AAPL']\n",
            "ADF Statistic: 2.756153\n",
            "p-value: 1.000000\n",
            "Critical Values:\n",
            "\t1%: -3.431\n",
            "\t5%: -2.862\n",
            "\t10%: -2.567\n",
            "Failed to reject Null Hypothesis. So, Time Series is Not-Stationary\n",
            "\n",
            "\n",
            "['AAPL2']\n",
            "ADF Statistic: 2.756153\n",
            "p-value: 1.000000\n",
            "Critical Values:\n",
            "\t1%: -3.431\n",
            "\t5%: -2.862\n",
            "\t10%: -2.567\n",
            "Failed to reject Null Hypothesis. So, Time Series is Not-Stationary\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in symbols:\n",
        "  print([i])\n",
        "  result = adfuller(df[i], autolag='AIC')\n",
        "  print('ADF Statistic: %f' % result[0])\n",
        "  print('p-value: %f' % result[1])\n",
        "  print('Critical Values:')\n",
        "  for key, value in result[4].items():\n",
        "      print('\\t%s: %.3f' % (key, value))\n",
        "  if result[0] < result[4][\"5%\"]:\n",
        "      print (\"Reject Null Hypothesis. So, Time Series is Stationary\")\n",
        "  else:\n",
        "      print (\"Failed to reject Null Hypothesis. So, Time Series is Not-Stationary\")\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cko7okIJtshP"
      },
      "source": [
        "## Normality Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GZtFd6K2Gpc",
        "outputId": "22ed0542-b99e-4436-ddfc-f9e9649c4527"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['SPX']\n",
            "Statistics=1911.944, p=0.000\n",
            "Critical Values:\n",
            "\t1%: -3.431\n",
            "\t5%: -2.862\n",
            "\t10%: -2.567\n",
            "Data is not normally distributed(reject H0)\n",
            "\n",
            "\n",
            "['AAPL']\n",
            "Statistics=3494.842, p=0.000\n",
            "Critical Values:\n",
            "\t1%: -3.431\n",
            "\t5%: -2.862\n",
            "\t10%: -2.567\n",
            "Data is not normally distributed(reject H0)\n",
            "\n",
            "\n",
            "['AAPL2']\n",
            "Statistics=3494.842, p=0.000\n",
            "Critical Values:\n",
            "\t1%: -3.431\n",
            "\t5%: -2.862\n",
            "\t10%: -2.567\n",
            "Data is not normally distributed(reject H0)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in symbols:\n",
        "    print([i])\n",
        "    stat, p = normaltest(df[i])\n",
        "    print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
        "    print('Critical Values:')\n",
        "    for key, value in result[4].items():\n",
        "        print('\\t%s: %.3f' % (key, value))\n",
        "    alpha = 0.05\n",
        "    if p > alpha:\n",
        "        print('Data is normally distributed (fail to reject H0)')\n",
        "    else:\n",
        "        print('Data is not normally distributed(reject H0)')\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXyOBVI7vQLS"
      },
      "source": [
        "#log Transformation\n",
        "The log transformation can be used to make highly skewed distributions less skewed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRk8mIQ8vkn4"
      },
      "source": [
        "#Using the log transformed data to do ADF and Normality test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CyBfmq0wB9Q"
      },
      "source": [
        "We can see that now the data for all three stocks is stationary. But, even if IUS4 is normally distributed, the other two are not. Have to look into why this is happening."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "VhzZduPZ-S9O"
      },
      "outputs": [],
      "source": [
        "from pmdarima import auto_arima\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score, mean_absolute_error\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhqHq_TIMwiP"
      },
      "outputs": [],
      "source": [
        "def arima_auto(arr, unscaled, name, prediction_size = 1): \n",
        "    train_data=pd.DataFrame()\n",
        "    test_data=pd.DataFrame() \n",
        "\n",
        "    unscaled_train=pd.DataFrame()\n",
        "    unscaled_test=pd.DataFrame() \n",
        "    split_index = int(len(arr)*0.9)\n",
        "    train_data, test_data = arr[:split_index], arr[split_index:]\n",
        "    unscaled_train, unscaled_test = unscaled[:split_index], unscaled[split_index:]\n",
        "    model = auto_arima(train_data, trace=True, stepwise=False, error_action='warn', max_p=10, max_d=5, max_q=10, max_D=2, max_P=5, max_Q=5, max_order=5)\n",
        "    model.fit(train_data) \n",
        "   \n",
        "    predictions = []\n",
        "    real = []\n",
        "\n",
        "    preds_test = []\n",
        "    real_test = []\n",
        "\n",
        "    for i in range(1, len(test_data) - prediction_size, prediction_size):\n",
        "        # Predict the next `prediction_size` steps\n",
        "        forecast_val = model.predict(n_periods=prediction_size)\n",
        "        \n",
        "        # Save predictions and actuals\n",
        "        predictions.extend(forecast_val)\n",
        "        real.extend(test_data.iloc[i:i+prediction_size].values)\n",
        "        \n",
        "        # Update the model with the latest `prediction_size` observed points\n",
        "        # AFTER they have been predicted (now part of the past)\n",
        "        model = model.update(test_data.iloc[i:i+prediction_size])\n",
        "        \n",
        "        preds_test.append((1+predictions[-1]) * unscaled_test.iloc[i+prediction_size-2])\n",
        "        real_test.append(unscaled_test.iloc[i+prediction_size-1])\n",
        "\n",
        "        print((1+predictions[-1]) * unscaled_test.iloc[i+prediction_size-2])\n",
        "        print(unscaled_test.iloc[i+prediction_size-1])\n",
        "\n",
        "    mape = mean_absolute_percentage_error(real_test, preds_test)\n",
        "    mse = mean_squared_error(real_test, preds_test)\n",
        "    r2 = r2_score(real_test, preds_test)\n",
        "    mae = mean_absolute_error(real_test, preds_test)\n",
        "    print(f\"{name} MAPE: {mape:.7f}% for forecast length: {prediction_size}\")\n",
        "    print(f\"{name} MSE: {mse:.5f} for forecast length: {prediction_size}\")\n",
        "    print(f\"{name} R2: {r2:.5f} for forecast length: {prediction_size}\")\n",
        "    print(f\"{name} MAE: {mae:.5f} for forecast length: {prediction_size}\")\n",
        "    \n",
        "    # Plotting\n",
        "#     plt.figure(figsize=(12,8))\n",
        "#     plt.plot(dates[::5], real[::5], label='Value')\n",
        "#     plt.plot(dates[::5], predictions[::5], label='Prediction')\n",
        "#     plt.title(f\"Return Prediction for {name}\")\n",
        "#     plt.xlabel('Date')\n",
        "#     plt.ylabel('Return ($)')\n",
        "#     handles, labels = plt.gca().get_legend_handles_labels()\n",
        "#     by_label = dict(zip(labels, handles))\n",
        "#     plt.legend(by_label.values(), by_label.keys())\n",
        "# #    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
        "#     plt.show()\n",
        "#     plt.close()\n",
        "    \n",
        "#     plt.figure(figsize=(12,8))\n",
        "#     plt.plot(dates[::5], unscaled_real[::5], label='Test')\n",
        "#     plt.plot(dates[::5], unscaled_predictions[::5], label='Prediction')\n",
        "#     handles, labels = plt.gca().get_legend_handles_labels()\n",
        "#     by_label = dict(zip(labels, handles))\n",
        "#     plt.legend(by_label.values(), by_label.keys())\n",
        "#     plt.title(f\"Stock Price Prediction for {name}\")\n",
        "#     plt.xlabel('Date')\n",
        "#     plt.ylabel('Stock Price ($)')\n",
        "#     plt.show()\n",
        "#     plt.close()\n",
        "\n",
        "\n",
        "    # predictions = []\n",
        "    # unscaled_predictions = []\n",
        "    # real_values = []\n",
        "    # unscaled_real_values = []\n",
        "    # dates = []\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 1) Fit the ARIMA model on your training set\n",
        "    # ---------------------------------------------------------\n",
        "    # model = auto_arima(\n",
        "    #     train_data, trace=True, \n",
        "    #     error_action='warn', max_order=5\n",
        "    # )\n",
        "    # model.fit(train_data)\n",
        "\n",
        "    # # ---------------------------------------------------------\n",
        "    # # 2) Keep track of the last known *unscaled* price\n",
        "    # #    (the final training-set price, for example)\n",
        "    # # ---------------------------------------------------------\n",
        "    # last_unscaled_price = unscaled_train.iloc[-1]\n",
        "\n",
        "    # # ---------------------------------------------------------\n",
        "    # # 3) Walk-forward over the test data in chunks of size `prediction_size`\n",
        "    # # ---------------------------------------------------------\n",
        "    # for i in range(0, len(test_data), prediction_size):\n",
        "    #     # --- A) Forecast out-of-sample (prediction_size steps ahead) ---\n",
        "    #     forecast_vals = model.predict(n_periods=prediction_size)\n",
        "        \n",
        "    #     # --- B) Store predictions and real values ---\n",
        "    #     for j, pred in enumerate(forecast_vals):\n",
        "    #         # If i + j exceeds test_data length, break\n",
        "    #         if i + j >= len(test_data):\n",
        "    #             break\n",
        "            \n",
        "    #         # 1) Save the predicted *scaled* value\n",
        "    #         predictions.append(pred)\n",
        "            \n",
        "    #         # 2) \"Unscale\" using the last known real price (NOT a future price!)\n",
        "    #         unscaled_pred = (1.0 + pred) * last_unscaled_price\n",
        "    #         unscaled_predictions.append(unscaled_pred)\n",
        "            \n",
        "    #         # 3) Get the real test data\n",
        "    #         real_val = test_data.iloc[i + j]\n",
        "    #         unscaled_val = unscaled_test.iloc[i + j]\n",
        "            \n",
        "    #         real_values.append(real_val)\n",
        "    #         unscaled_real_values.append(unscaled_val)\n",
        "    #         dates.append(unscaled_test.index[i + j])\n",
        "            \n",
        "    #         # 4) IMPORTANT: Now that \"time i+j\" has *actually occurred*, \n",
        "    #         #               you can update last_unscaled_price\n",
        "    #         last_unscaled_price = unscaled_val\n",
        "        \n",
        "    #     # --- C) Only AFTER forecasting, update the ARIMA model with the \n",
        "    #     #         newly observed chunk of test data. This is the crucial step\n",
        "    #     #         to prevent leaking future info into your model.\n",
        "    #     # ---\n",
        "    #     #  (Note: if i+prediction_size > len(test_data), it will just update\n",
        "    #     #   with however many points remain)\n",
        "    #     new_data_chunk = test_data.iloc[i : i + prediction_size]\n",
        "    #     model = model.update(new_data_chunk)\n",
        "    #     if i % 50 == 0:\n",
        "    #         print(i)\n",
        "\n",
        "    # # ---------------------------------------------------------\n",
        "    # # 4) Compute your errors on out-of-sample predictions\n",
        "    # # ---------------------------------------------------------\n",
        "    # mape = mean_absolute_percentage_error(unscaled_real_values, unscaled_predictions)\n",
        "    # mse  = mean_squared_error(unscaled_real_values, unscaled_predictions)\n",
        "    # r2   = r2_score(unscaled_real_values, unscaled_predictions)\n",
        "    # mae  = mean_absolute_error(unscaled_real_values, unscaled_predictions)\n",
        "    \n",
        "    return (mape, mse, r2, mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B91V8iPB5r8S"
      },
      "source": [
        "Best fit ARIMA (p,d,q) parameters:\n",
        "* EXX5 : (1,1,1)\n",
        "* IQQE : (0,1,0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Below is the same process but using interday change instead of log transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfs = {'SPX': df1, 'AAPL': df2, \"TWSE\" : df3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ARIMA(0,0,0)(0,0,0)[1] intercept   : AIC=-48509.365, Time=0.29 sec\n",
            " ARIMA(0,0,1)(0,0,0)[1] intercept   : AIC=-48572.181, Time=0.54 sec\n",
            " ARIMA(0,0,2)(0,0,0)[1] intercept   : AIC=-48570.743, Time=0.83 sec\n",
            " ARIMA(0,0,3)(0,0,0)[1] intercept   : AIC=-48568.897, Time=1.59 sec\n",
            " ARIMA(0,0,4)(0,0,0)[1] intercept   : AIC=-48573.710, Time=1.22 sec\n",
            " ARIMA(0,0,5)(0,0,0)[1] intercept   : AIC=-48576.461, Time=1.34 sec\n",
            " ARIMA(1,0,0)(0,0,0)[1] intercept   : AIC=-48570.667, Time=0.37 sec\n",
            " ARIMA(1,0,1)(0,0,0)[1] intercept   : AIC=-48570.818, Time=0.67 sec\n",
            " ARIMA(1,0,2)(0,0,0)[1] intercept   : AIC=-48574.126, Time=0.62 sec\n",
            " ARIMA(1,0,3)(0,0,0)[1] intercept   : AIC=-48567.835, Time=1.14 sec\n",
            " ARIMA(1,0,4)(0,0,0)[1] intercept   : AIC=-48570.771, Time=1.44 sec\n",
            " ARIMA(2,0,0)(0,0,0)[1] intercept   : AIC=-48570.568, Time=0.33 sec\n",
            " ARIMA(2,0,1)(0,0,0)[1] intercept   : AIC=-48568.751, Time=0.80 sec\n",
            " ARIMA(2,0,2)(0,0,0)[1] intercept   : AIC=-48574.455, Time=1.11 sec\n",
            " ARIMA(2,0,3)(0,0,0)[1] intercept   : AIC=-48570.571, Time=1.38 sec\n",
            " ARIMA(3,0,0)(0,0,0)[1] intercept   : AIC=-48568.602, Time=0.51 sec\n",
            " ARIMA(3,0,1)(0,0,0)[1] intercept   : AIC=-48566.638, Time=1.01 sec\n",
            " ARIMA(3,0,2)(0,0,0)[1] intercept   : AIC=-48564.673, Time=1.74 sec\n",
            " ARIMA(4,0,0)(0,0,0)[1] intercept   : AIC=-48571.308, Time=1.29 sec\n",
            " ARIMA(4,0,1)(0,0,0)[1] intercept   : AIC=-48569.765, Time=1.14 sec\n",
            " ARIMA(5,0,0)(0,0,0)[1] intercept   : AIC=-48574.179, Time=1.09 sec\n",
            "\n",
            "Best model:  ARIMA(0,0,5)(0,0,0)[1] intercept\n",
            "Total fit time: 20.461 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sunilcotterill/Library/Python/3.10/lib/python/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
            "  return get_prediction_index(\n",
            "/Users/sunilcotterill/Library/Python/3.10/lib/python/site-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
            "  return get_prediction_index(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Close    4361.090228\n",
            "Name: 2021-09-29 00:00:00, dtype: float64\n",
            "Close    4307.54\n",
            "Name: 2021-09-30 00:00:00, dtype: float64\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "cannot unpack non-iterable NoneType object",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[57], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m df_interday \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mpct_change()  \u001b[38;5;66;03m# This computes (Price_t - Price_(t-1)) / Price_(t-1)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m df_interday \u001b[38;5;241m=\u001b[39m df_interday\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m----> 8\u001b[0m mape, mse, r2, mae \u001b[38;5;241m=\u001b[39m arima_auto(df_interday, df_adj, name, \u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m      9\u001b[0m res\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m: name,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction_Size\u001b[39m\u001b[38;5;124m\"\u001b[39m: pred_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m\"\u001b[39m: r2\n\u001b[1;32m     16\u001b[0m })\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(res)\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ],
      "source": [
        "res = []\n",
        "for name in dfs:\n",
        "    for pred_size in [10]:\n",
        "        df = dfs[name]\n",
        "        df_adj = df.iloc[1::]\n",
        "        df_interday = df.pct_change()  # This computes (Price_t - Price_(t-1)) / Price_(t-1)\n",
        "        df_interday = df_interday.dropna()\n",
        "        mape, mse, r2, mae = arima_auto(df_interday, df_adj, name, pred_size)\n",
        "        res.append({\n",
        "            \"DataFrame\": name,\n",
        "            \"Prediction_Size\": pred_size,\n",
        "            \"MAE\": mae,\n",
        "            \"MSE\": mse,\n",
        "            \"MAPE\": mape,\n",
        "            \"r2\": r2\n",
        "        })\n",
        "\n",
        "        print(res)\n",
        "\n",
        "\n",
        "results_df = pd.DataFrame(res)\n",
        "results_df.to_csv(\"arima_errors.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Timestamp</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1990-01-04</th>\n",
              "      <td>9853.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990-01-05</th>\n",
              "      <td>9862.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990-01-06</th>\n",
              "      <td>9927.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990-01-08</th>\n",
              "      <td>9964.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990-01-09</th>\n",
              "      <td>9805.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-01-16</th>\n",
              "      <td>23025.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-01-17</th>\n",
              "      <td>23148.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-01-20</th>\n",
              "      <td>23266.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-01-21</th>\n",
              "      <td>23300.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-01-22</th>\n",
              "      <td>23525.41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9024 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               Close\n",
              "Timestamp           \n",
              "1990-01-04   9853.15\n",
              "1990-01-05   9862.42\n",
              "1990-01-06   9927.06\n",
              "1990-01-08   9964.72\n",
              "1990-01-09   9805.40\n",
              "...              ...\n",
              "2025-01-16  23025.10\n",
              "2025-01-17  23148.08\n",
              "2025-01-20  23266.82\n",
              "2025-01-21  23300.01\n",
              "2025-01-22  23525.41\n",
              "\n",
              "[9024 rows x 1 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3 = pd.read_csv(\"./data/TWSE_Real.csv\")\n",
        "df3.columns = ['Timestamp', 'Close']\n",
        "df3.set_index(\"Timestamp\", inplace=True)\n",
        "df3.index = pd.to_datetime(df3.index, format='%m/%d/%Y')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ARIMA(0,0,0)(0,0,0)[1] intercept   : AIC=87189.385, Time=0.06 sec\n",
            " ARIMA(0,0,1)(0,0,0)[1] intercept   : AIC=87161.018, Time=0.16 sec\n",
            " ARIMA(0,0,2)(0,0,0)[1] intercept   : AIC=87162.879, Time=0.28 sec\n",
            " ARIMA(0,0,3)(0,0,0)[1] intercept   : AIC=87147.859, Time=0.35 sec\n",
            " ARIMA(0,0,4)(0,0,0)[1] intercept   : AIC=87141.683, Time=0.48 sec\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[39], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m df_interday \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdiff()\n\u001b[1;32m      6\u001b[0m df_interday \u001b[38;5;241m=\u001b[39m df_interday\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m----> 7\u001b[0m \u001b[43marima_auto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_interday\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_adj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[28], line 10\u001b[0m, in \u001b[0;36marima_auto\u001b[0;34m(arr, unscaled, name, prediction_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m train_data, test_data \u001b[38;5;241m=\u001b[39m arr[:split_index], arr[split_index:]\n\u001b[1;32m      9\u001b[0m unscaled_train, unscaled_test \u001b[38;5;241m=\u001b[39m unscaled[:split_index], unscaled[split_index:]\n\u001b[0;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mauto_arima\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstepwise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwarn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_q\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_D\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_P\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_Q\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_data) \n\u001b[1;32m     13\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pmdarima/arima/auto.py:701\u001b[0m, in \u001b[0;36mauto_arima\u001b[0;34m(y, X, start_p, d, start_q, max_p, max_d, max_q, start_P, D, start_Q, max_P, max_D, max_Q, max_order, m, seasonal, stationary, information_criterion, alpha, test, seasonal_test, stepwise, n_jobs, start_params, trend, method, maxiter, offset_test_args, seasonal_test_args, suppress_warnings, error_action, trace, random, random_state, n_fits, return_valid_fits, out_of_sample_size, scoring, scoring_args, with_intercept, sarimax_kwargs, **fit_args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;66;03m# init the stepwise model wrapper\u001b[39;00m\n\u001b[1;32m    670\u001b[0m     search \u001b[38;5;241m=\u001b[39m solvers\u001b[38;5;241m.\u001b[39m_StepwiseFitWrapper(\n\u001b[1;32m    671\u001b[0m         y,\n\u001b[1;32m    672\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msarimax_kwargs,\n\u001b[1;32m    699\u001b[0m     )\n\u001b[0;32m--> 701\u001b[0m sorted_res \u001b[38;5;241m=\u001b[39m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _return_wrapper(sorted_res, return_valid_fits, start, trace)\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pmdarima/arima/_auto_solvers.py:127\u001b[0m, in \u001b[0;36m_RandomFitWrapper.solve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# get results in parallel\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m all_res \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfit_partial\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseasonal_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseasonal_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseasonal_order\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m sorted_fits \u001b[38;5;241m=\u001b[39m _sort_and_filter_fits(all_res)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace \u001b[38;5;129;01mand\u001b[39;00m sorted_fits:\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pmdarima/arima/_auto_solvers.py:508\u001b[0m, in \u001b[0;36m_fit_candidate_model\u001b[0;34m(y, X, order, seasonal_order, start_params, trend, method, maxiter, fit_params, suppress_warnings, trace, error_action, out_of_sample_size, scoring, scoring_args, with_intercept, information_criterion, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m fit \u001b[38;5;241m=\u001b[39m ARIMA(order\u001b[38;5;241m=\u001b[39morder, seasonal_order\u001b[38;5;241m=\u001b[39mseasonal_order,\n\u001b[1;32m    501\u001b[0m             start_params\u001b[38;5;241m=\u001b[39mstart_params, trend\u001b[38;5;241m=\u001b[39mtrend, method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    502\u001b[0m             maxiter\u001b[38;5;241m=\u001b[39mmaxiter, suppress_warnings\u001b[38;5;241m=\u001b[39msuppress_warnings,\n\u001b[1;32m    503\u001b[0m             out_of_sample_size\u001b[38;5;241m=\u001b[39mout_of_sample_size, scoring\u001b[38;5;241m=\u001b[39mscoring,\n\u001b[1;32m    504\u001b[0m             scoring_args\u001b[38;5;241m=\u001b[39mscoring_args,\n\u001b[1;32m    505\u001b[0m             with_intercept\u001b[38;5;241m=\u001b[39mwith_intercept, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 508\u001b[0m     \u001b[43mfit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# for non-stationarity errors or singular matrices, return None\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (LinAlgError, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m v:\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pmdarima/arima/arima.py:603\u001b[0m, in \u001b[0;36mARIMA.fit\u001b[0;34m(self, y, X, **fit_args)\u001b[0m\n\u001b[1;32m    600\u001b[0m         X \u001b[38;5;241m=\u001b[39m safe_indexing(X, \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, n_exog \u001b[38;5;241m-\u001b[39m cv))\n\u001b[1;32m    602\u001b[0m \u001b[38;5;66;03m# Internal call\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;66;03m# now make a forecast if we're validating to compute the\u001b[39;00m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;66;03m# out-of-sample score\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;66;03m# get the predictions (use self.predict, which calls forecast\u001b[39;00m\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;66;03m# from statsmodels internally)\u001b[39;00m\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pmdarima/arima/arima.py:524\u001b[0m, in \u001b[0;36mARIMA._fit\u001b[0;34m(self, y, X, **fit_args)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    523\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 524\u001b[0m         fit, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marima_res_ \u001b[38;5;241m=\u001b[39m \u001b[43m_fit_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    526\u001b[0m     fit, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marima_res_ \u001b[38;5;241m=\u001b[39m _fit_wrapper()\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pmdarima/arima/arima.py:510\u001b[0m, in \u001b[0;36mARIMA._fit.<locals>._fit_wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m    507\u001b[0m _maxiter \u001b[38;5;241m=\u001b[39m fit_args\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m\"\u001b[39m, _maxiter)\n\u001b[1;32m    509\u001b[0m disp \u001b[38;5;241m=\u001b[39m fit_args\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 510\u001b[0m fitted \u001b[38;5;241m=\u001b[39m \u001b[43marima\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_maxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arima, fitted\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/statsmodels/tsa/statespace/mlemodel.py:705\u001b[0m, in \u001b[0;36mMLEModel.fit\u001b[0;34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m         flags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhessian_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m optim_hessian\n\u001b[1;32m    704\u001b[0m     fargs \u001b[38;5;241m=\u001b[39m (flags,)\n\u001b[0;32m--> 705\u001b[0m     mlefit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mskip_hessian\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;66;03m# Just return the fitted parameters if requested\u001b[39;00m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_params:\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/statsmodels/base/model.py:566\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_t\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    565\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Optimizer()\n\u001b[0;32m--> 566\u001b[0m xopt, retvals, optim_settings \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mhessian\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mretall\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;66;03m# Restore cov_type, cov_kwds and use_t\u001b[39;00m\n\u001b[1;32m    576\u001b[0m optim_settings\u001b[38;5;241m.\u001b[39mupdate(kwds)\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/statsmodels/base/optimizer.py:243\u001b[0m, in \u001b[0;36mOptimizer._fit\u001b[0;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[1;32m    240\u001b[0m     fit_funcs\u001b[38;5;241m.\u001b[39mupdate(extra_fit_funcs)\n\u001b[1;32m    242\u001b[0m func \u001b[38;5;241m=\u001b[39m fit_funcs[method]\n\u001b[0;32m--> 243\u001b[0m xopt, retvals \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mretall\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mhess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhessian\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m optim_settings \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: method, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_params\u001b[39m\u001b[38;5;124m'\u001b[39m: start_params,\n\u001b[1;32m    249\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m'\u001b[39m: maxiter, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_output\u001b[39m\u001b[38;5;124m'\u001b[39m: full_output,\n\u001b[1;32m    250\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: disp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfargs\u001b[39m\u001b[38;5;124m'\u001b[39m: fargs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m'\u001b[39m: callback,\n\u001b[1;32m    251\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretall\u001b[39m\u001b[38;5;124m'\u001b[39m: retall, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_fit_funcs\u001b[39m\u001b[38;5;124m\"\u001b[39m: extra_fit_funcs}\n\u001b[1;32m    252\u001b[0m optim_settings\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/statsmodels/base/optimizer.py:660\u001b[0m, in \u001b[0;36m_fit_lbfgs\u001b[0;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m approx_grad:\n\u001b[1;32m    658\u001b[0m     func \u001b[38;5;241m=\u001b[39m f\n\u001b[0;32m--> 660\u001b[0m retvals \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin_l_bfgs_b\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m                                 \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_output:\n\u001b[1;32m    666\u001b[0m     xopt, fopt, d \u001b[38;5;241m=\u001b[39m retvals\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/scipy/optimize/_lbfgsb_py.py:199\u001b[0m, in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    187\u001b[0m callback \u001b[38;5;241m=\u001b[39m _wrap_callback(callback)\n\u001b[1;32m    188\u001b[0m opts \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: disp,\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miprint\u001b[39m\u001b[38;5;124m'\u001b[39m: iprint,\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxcor\u001b[39m\u001b[38;5;124m'\u001b[39m: m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m'\u001b[39m: callback,\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxls\u001b[39m\u001b[38;5;124m'\u001b[39m: maxls}\n\u001b[0;32m--> 199\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m d \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrad\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjac\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    202\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    203\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfuncalls\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnfev\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    204\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnit\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnit\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    205\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarnflag\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m    206\u001b[0m f \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfun\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/scipy/optimize/_lbfgsb_py.py:369\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    363\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    372\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/scipy/optimize/_differentiable_functions.py:297\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/scipy/optimize/_differentiable_functions.py:267\u001b[0m, in \u001b[0;36mScalarFunction._update_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated:\n\u001b[0;32m--> 267\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/scipy/optimize/_differentiable_functions.py:181\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_grad\u001b[0;34m()\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m \u001b[43mapprox_derivative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfinite_diff_options\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/scipy/optimize/_numdiff.py:519\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[0;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[1;32m    516\u001b[0m     use_one_sided \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparsity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_dense_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m                             \u001b[49m\u001b[43muse_one_sided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(sparsity) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparsity) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/scipy/optimize/_numdiff.py:590\u001b[0m, in \u001b[0;36m_dense_difference\u001b[0;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[1;32m    588\u001b[0m     x \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n\u001b[1;32m    589\u001b[0m     dx \u001b[38;5;241m=\u001b[39m x[i] \u001b[38;5;241m-\u001b[39m x0[i]  \u001b[38;5;66;03m# Recompute dx as exactly representable number.\u001b[39;00m\n\u001b[0;32m--> 590\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m f0\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3-point\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m use_one_sided[i]:\n\u001b[1;32m    592\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/scipy/optimize/_numdiff.py:470\u001b[0m, in \u001b[0;36mapprox_derivative.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39misdtype(x\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal floating\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    468\u001b[0m     x \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(x, x0\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 470\u001b[0m f \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`fun` return value has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    473\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmore than 1 dimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/scipy/optimize/_differentiable_functions.py:145\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/statsmodels/base/model.py:534\u001b[0m, in \u001b[0;36mLikelihoodModel.fit.<locals>.f\u001b[0;34m(params, *args)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(params, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 534\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloglike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m nobs\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/statsmodels/tsa/statespace/mlemodel.py:940\u001b[0m, in \u001b[0;36mMLEModel.loglike\u001b[0;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m complex_step:\n\u001b[1;32m    938\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minversion_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m INVERT_UNIVARIATE \u001b[38;5;241m|\u001b[39m SOLVE_LU\n\u001b[0;32m--> 940\u001b[0m loglike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloglike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomplex_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomplex_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;66;03m# Koopman, Shephard, and Doornik recommend maximizing the average\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;66;03m# likelihood to avoid scale issues, but the averaging is done\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;66;03m# automatically in the base model `fit` method\u001b[39;00m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loglike\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/statsmodels/tsa/statespace/kalman_filter.py:1001\u001b[0m, in \u001b[0;36mKalmanFilter.loglike\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;124;03mCalculate the loglikelihood associated with the statespace model.\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;124;03m    The joint loglikelihood.\u001b[39;00m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    999\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconserve_memory\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1000\u001b[0m                   MEMORY_CONSERVE \u001b[38;5;241m^\u001b[39m MEMORY_NO_LIKELIHOOD)\n\u001b[0;32m-> 1001\u001b[0m kfilter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1002\u001b[0m loglikelihood_burn \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloglikelihood_burn\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1003\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloglikelihood_burn)\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconserve_memory\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m&\u001b[39m MEMORY_NO_LIKELIHOOD):\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/statsmodels/tsa/statespace/kalman_filter.py:924\u001b[0m, in \u001b[0;36mKalmanFilter._filter\u001b[0;34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_state(prefix\u001b[38;5;241m=\u001b[39mprefix, complex_step\u001b[38;5;241m=\u001b[39mcomplex_step)\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Run the filter\u001b[39;00m\n\u001b[0;32m--> 924\u001b[0m \u001b[43mkfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m kfilter\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "df3_dict = {\"TWSE\" : df3}\n",
        "for name in df3_dict:\n",
        "    df = df3_dict[name]\n",
        "    df_adj = df.iloc[1::]\n",
        "    df_interday = df.diff()\n",
        "    df_interday = df_interday.dropna()\n",
        "    arima_auto(df_interday, df_adj, name)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Stock_price_forecasting.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
