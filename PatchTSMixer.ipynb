{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import normaltest\n",
    "from statsmodels.tsa.stattools import acf,pacf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./data/SPX_Real.csv\", index_col=False)\n",
    "df1.columns = ['Timestamp', 'Close']\n",
    "df1.set_index(\"Timestamp\", inplace=True)\n",
    "df1.index = pd.to_datetime(df1.index, format='%d-%m-%Y')\n",
    "df2 = pd.read_csv(\"./data/AAPL_Real.csv\")\n",
    "df2.columns = ['Timestamp', 'Close']\n",
    "df2.set_index(\"Timestamp\", inplace=True)\n",
    "df2.index = pd.to_datetime(df2.index, format='%d-%m-%Y')\n",
    "df3 = pd.read_csv(\"./data/TWSE_Real.csv\")\n",
    "df3.columns = ['Timestamp', 'Close']\n",
    "df3.set_index(\"Timestamp\", inplace=True)\n",
    "df3.index = pd.to_datetime(df3.index, format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def create_dataset(series, window_size, pred_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(series) - window_size - pred_length + 1):\n",
    "        X.append(series[i : i + window_size])\n",
    "        y.append(series[i + window_size : i + window_size + pred_length])\n",
    "    \n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def get_data_for_period(df, window_size = 20, pred_length = 1):    \n",
    "    val_start = int(len(df) * 0.8)\n",
    "    test_start = val_start + int(len(df) * 0.1)\n",
    "    train_data = df.iloc[:val_start]\n",
    "    val_data   = df.iloc[val_start:test_start]\n",
    "    test_data  = df.iloc[test_start:]\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_values = train_data['Close'].values.reshape(-1, 1)\n",
    "    scaler.fit(train_values)\n",
    "    \n",
    "    train_scaled = scaler.transform(train_data['Close'].values.reshape(-1, 1)).flatten()\n",
    "    val_scaled   = scaler.transform(val_data['Close'].values.reshape(-1, 1)).flatten()\n",
    "    test_scaled  = scaler.transform(test_data['Close'].values.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    X_train, y_train = create_dataset(train_scaled, window_size, pred_length)\n",
    "    X_val, y_val     = create_dataset(val_scaled, window_size, pred_length)\n",
    "    X_test, y_test   = create_dataset(test_scaled, window_size, pred_length)\n",
    "    \n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test), scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {'SPX': df1, 'AAPL': df2, 'TWSE': df3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X  \n",
    "        self.Y = Y  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        past_vals = torch.tensor(self.X[idx], dtype=torch.float32).unsqueeze(-1)\n",
    "        future_vals = torch.tensor(self.Y[idx], dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "        return {\n",
    "            \"past_values\": past_vals,     \n",
    "            \"future_values\": future_vals   \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunilcotterill/Library/Python/3.10/lib/python/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "[codecarbon ERROR @ 05:48:20] Error: Another instance of codecarbon is already running. Turn off the other instance to be able to run this one. Exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past_values batch shape: torch.Size([32, 55, 1])\n",
      "future_values batch shape: torch.Size([32, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 05:48:20] Another instance of codecarbon is already running. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4400' max='4400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4400/4400 03:30, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.002938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.002344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.001816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.001429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 05:51:51] Another instance of codecarbon is already running. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunilcotterill/Library/Python/3.10/lib/python/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "[codecarbon ERROR @ 05:51:51] Error: Another instance of codecarbon is already running. Turn off the other instance to be able to run this one. Exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: {'eval_loss': 0.0012304793344810605, 'eval_runtime': 0.2709, 'eval_samples_per_second': 3060.148, 'eval_steps_per_second': 95.976, 'epoch': 20.0}\n",
      "past_values batch shape: torch.Size([32, 55, 1])\n",
      "future_values batch shape: torch.Size([32, 5, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 05:51:52] Another instance of codecarbon is already running. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4380' max='4380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4380/4380 03:30, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.003228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.002716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.002348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.002099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.001930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.001803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.001701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.001497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.001390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 05:55:22] Another instance of codecarbon is already running. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunilcotterill/Library/Python/3.10/lib/python/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "[codecarbon ERROR @ 05:55:23] Error: Another instance of codecarbon is already running. Turn off the other instance to be able to run this one. Exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: {'eval_loss': 0.001950511010363698, 'eval_runtime': 0.2958, 'eval_samples_per_second': 2788.615, 'eval_steps_per_second': 87.884, 'epoch': 20.0}\n",
      "past_values batch shape: torch.Size([32, 55, 1])\n",
      "future_values batch shape: torch.Size([32, 10, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 05:55:23] Another instance of codecarbon is already running. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4380' max='4380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4380/4380 03:40, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.003752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.003233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.002853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.002596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.002428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.002306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.002211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.002135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.002074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.002024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.001985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.001953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.001928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.001910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.001897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.001888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.001883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.001880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.001879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.001879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 05:59:04] Another instance of codecarbon is already running. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunilcotterill/Library/Python/3.10/lib/python/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "[codecarbon ERROR @ 05:59:05] Error: Another instance of codecarbon is already running. Turn off the other instance to be able to run this one. Exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: {'eval_loss': 0.002737656468525529, 'eval_runtime': 0.4681, 'eval_samples_per_second': 1751.657, 'eval_steps_per_second': 55.54, 'epoch': 20.0}\n",
      "past_values batch shape: torch.Size([32, 55, 1])\n",
      "future_values batch shape: torch.Size([32, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 05:59:05] Another instance of codecarbon is already running. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4400' max='4400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4400/4400 03:43, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.021382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.015392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.011709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.009522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.008271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.007496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.006951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.006513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.006166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.005893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.005694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.005524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.005384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.005283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.005204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.005151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.005118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.005100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.005094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.005093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 06:02:49] Another instance of codecarbon is already running. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunilcotterill/Library/Python/3.10/lib/python/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "[codecarbon ERROR @ 06:02:49] Error: Another instance of codecarbon is already running. Turn off the other instance to be able to run this one. Exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: {'eval_loss': 0.015614773146808147, 'eval_runtime': 0.2764, 'eval_samples_per_second': 2999.017, 'eval_steps_per_second': 94.058, 'epoch': 20.0}\n",
      "past_values batch shape: torch.Size([32, 55, 1])\n",
      "future_values batch shape: torch.Size([32, 5, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 06:02:50] Another instance of codecarbon is already running. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4380' max='4380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4380/4380 03:39, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.021987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.018326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.015595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.013759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.012566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.011710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.011055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.010532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.010110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.009779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.009507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.009302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.009143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.009017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.008926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.008865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.008828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.008809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.008802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.008801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 06:06:30] Another instance of codecarbon is already running. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunilcotterill/Library/Python/3.10/lib/python/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "[codecarbon ERROR @ 06:06:30] Error: Another instance of codecarbon is already running. Turn off the other instance to be able to run this one. Exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: {'eval_loss': 0.02598980814218521, 'eval_runtime': 0.2976, 'eval_samples_per_second': 2771.713, 'eval_steps_per_second': 87.351, 'epoch': 20.0}\n",
      "past_values batch shape: torch.Size([32, 55, 1])\n",
      "future_values batch shape: torch.Size([32, 10, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 06:06:31] Another instance of codecarbon is already running. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4380' max='4380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4380/4380 03:39, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.025914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.022009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.019118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.017213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.015998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.015156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.014554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.014077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.013698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.013403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.013156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.012974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.012830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.012719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.012640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.012585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.012554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.012537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.012531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.012530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 06:10:10] Another instance of codecarbon is already running. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunilcotterill/Library/Python/3.10/lib/python/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "[codecarbon ERROR @ 06:10:10] Error: Another instance of codecarbon is already running. Turn off the other instance to be able to run this one. Exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: {'eval_loss': 0.035511232912540436, 'eval_runtime': 0.28, 'eval_samples_per_second': 2928.864, 'eval_steps_per_second': 92.866, 'epoch': 20.0}\n",
      "past_values batch shape: torch.Size([32, 55, 1])\n",
      "future_values batch shape: torch.Size([32, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 06:10:11] Another instance of codecarbon is already running. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4480' max='4480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4480/4480 03:41, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.002831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.002116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.001203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 06:13:53] Another instance of codecarbon is already running. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunilcotterill/Library/Python/3.10/lib/python/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "[codecarbon ERROR @ 06:13:53] Error: Another instance of codecarbon is already running. Turn off the other instance to be able to run this one. Exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: {'eval_loss': 0.0015649728011339903, 'eval_runtime': 0.3067, 'eval_samples_per_second': 2764.635, 'eval_steps_per_second': 88.025, 'epoch': 20.0}\n",
      "past_values batch shape: torch.Size([32, 55, 1])\n",
      "future_values batch shape: torch.Size([32, 5, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 06:13:54] Another instance of codecarbon is already running. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4480' max='4480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4480/4480 03:42, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.002738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.002243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.001898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.001552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.001464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.001395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.001292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.001252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.001157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.001146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.001133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.001130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.001129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.001129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 06:17:36] Another instance of codecarbon is already running. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunilcotterill/Library/Python/3.10/lib/python/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "[codecarbon ERROR @ 06:17:37] Error: Another instance of codecarbon is already running. Turn off the other instance to be able to run this one. Exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: {'eval_loss': 0.002614461351186037, 'eval_runtime': 0.3926, 'eval_samples_per_second': 2149.601, 'eval_steps_per_second': 68.767, 'epoch': 20.0}\n",
      "past_values batch shape: torch.Size([32, 55, 1])\n",
      "future_values batch shape: torch.Size([32, 10, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 06:17:37] Another instance of codecarbon is already running. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4480' max='4480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4480/4480 03:43, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.003341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.002813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.002419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.002180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.002034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.001941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.001874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.001818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.001775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.001740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.001710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.001652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.001641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.001634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.001630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.001627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 06:21:21] Another instance of codecarbon is already running. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: {'eval_loss': 0.0037439947482198477, 'eval_runtime': 0.3138, 'eval_samples_per_second': 2673.925, 'eval_steps_per_second': 86.05, 'epoch': 20.0}\n",
      "{'SPX_pred_length_1': {'eval_loss': 0.0012304793344810605, 'eval_runtime': 0.2709, 'eval_samples_per_second': 3060.148, 'eval_steps_per_second': 95.976, 'epoch': 20.0}, 'SPX_pred_length_5': {'eval_loss': 0.001950511010363698, 'eval_runtime': 0.2958, 'eval_samples_per_second': 2788.615, 'eval_steps_per_second': 87.884, 'epoch': 20.0}, 'SPX_pred_length_10': {'eval_loss': 0.002737656468525529, 'eval_runtime': 0.4681, 'eval_samples_per_second': 1751.657, 'eval_steps_per_second': 55.54, 'epoch': 20.0}, 'AAPL_pred_length_1': {'eval_loss': 0.015614773146808147, 'eval_runtime': 0.2764, 'eval_samples_per_second': 2999.017, 'eval_steps_per_second': 94.058, 'epoch': 20.0}, 'AAPL_pred_length_5': {'eval_loss': 0.02598980814218521, 'eval_runtime': 0.2976, 'eval_samples_per_second': 2771.713, 'eval_steps_per_second': 87.351, 'epoch': 20.0}, 'AAPL_pred_length_10': {'eval_loss': 0.035511232912540436, 'eval_runtime': 0.28, 'eval_samples_per_second': 2928.864, 'eval_steps_per_second': 92.866, 'epoch': 20.0}, 'TWSE_pred_length_1': {'eval_loss': 0.0015649728011339903, 'eval_runtime': 0.3067, 'eval_samples_per_second': 2764.635, 'eval_steps_per_second': 88.025, 'epoch': 20.0}, 'TWSE_pred_length_5': {'eval_loss': 0.002614461351186037, 'eval_runtime': 0.3926, 'eval_samples_per_second': 2149.601, 'eval_steps_per_second': 68.767, 'epoch': 20.0}, 'TWSE_pred_length_10': {'eval_loss': 0.0037439947482198477, 'eval_runtime': 0.3138, 'eval_samples_per_second': 2673.925, 'eval_steps_per_second': 86.05, 'epoch': 20.0}}\n"
     ]
    }
   ],
   "source": [
    "from transformers import PatchTSMixerConfig, PatchTSMixerForPrediction\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "res = {}\n",
    "window_size = 55\n",
    "for name in dfs:\n",
    "    for pred_length in [1, 5, 10]:\n",
    "        (X_train, y_train), (X_val, y_val), (X_test, y_test), scaler = get_data_for_period(dfs[name], window_size, pred_length)\n",
    "        train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "        valid_dataset = TimeSeriesDataset(X_val, y_val)\n",
    "        test_dataset  = TimeSeriesDataset(X_test, y_test)\n",
    "\n",
    "        loader = DataLoader(train_dataset, batch_size=32)\n",
    "        batch = next(iter(loader))\n",
    "        config = PatchTSMixerConfig(context_length = 55, prediction_length = pred_length, num_input_channels=1)\n",
    "        model = PatchTSMixerForPrediction(config)\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=f\"./20_pochs_patch_tsm_results_{name}_pred_length_{pred_length}\",\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            per_device_train_batch_size=32,\n",
    "            per_device_eval_batch_size=32,\n",
    "            num_train_epochs=20,\n",
    "            auto_find_batch_size = True,\n",
    "            lr_scheduler_type = \"cosine\",\n",
    "            logging_steps=10,\n",
    "            save_strategy=\"epoch\",\n",
    "            label_smoothing_factor = 0.1\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,   \n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "        results = trainer.evaluate(test_dataset)\n",
    "        print(\"Test results:\", results)\n",
    "        res[f\"{name}_pred_length_{pred_length}\"] = results\n",
    "\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model is from checkpoint: ./20_pochs_patch_tsm_results_SPX_pred_length_1/checkpoint-4400 with MSE: 0.0008\n",
      "(829, 1)\n",
      "SPX RMSE: 94.84379577636719 for 1\n",
      "SPX MAE: 75.76220703125 for 1\n",
      "SPX MAPE: 1.6895703971385956 for 1\n",
      "SPX r2: 0.9791280627250671 for 1\n",
      "\n",
      "Best model is from checkpoint: ./20_pochs_patch_tsm_results_SPX_pred_length_5/checkpoint-4380 with MSE: 0.0013\n",
      "(4125, 1)\n",
      "SPX RMSE: 150.35609436035156 for 5\n",
      "SPX MAE: 125.94324493408203 for 5\n",
      "SPX MAPE: 2.8022438287734985 for 5\n",
      "SPX r2: 0.9471405744552612 for 5\n",
      "\n",
      "Best model is from checkpoint: ./20_pochs_patch_tsm_results_SPX_pred_length_10/checkpoint-4380 with MSE: 0.0019\n",
      "(8200, 1)\n",
      "SPX RMSE: 164.12283325195312 for 10\n",
      "SPX MAE: 138.55908203125 for 10\n",
      "SPX MAPE: 3.0737869441509247 for 10\n",
      "SPX r2: 0.9365258812904358 for 10\n",
      "\n",
      "Best model is from checkpoint: ./20_pochs_patch_tsm_results_AAPL_pred_length_1/checkpoint-4400 with MSE: 0.0051\n",
      "(829, 1)\n",
      "AAPL RMSE: 6.276037216186523 for 1\n",
      "AAPL MAE: 5.052524089813232 for 1\n",
      "AAPL MAPE: 2.898608334362507 for 1\n",
      "AAPL r2: 0.9544966816902161 for 1\n",
      "\n",
      "Best model is from checkpoint: ./20_pochs_patch_tsm_results_AAPL_pred_length_5/checkpoint-4380 with MSE: 0.0088\n",
      "(4125, 1)\n",
      "AAPL RMSE: 9.834284782409668 for 5\n",
      "AAPL MAE: 8.130414009094238 for 5\n",
      "AAPL MAPE: 4.683298617601395 for 5\n",
      "AAPL r2: 0.887779951095581 for 5\n",
      "\n",
      "Best model is from checkpoint: ./20_pochs_patch_tsm_results_AAPL_pred_length_10/checkpoint-4380 with MSE: 0.0125\n",
      "(8200, 1)\n",
      "AAPL RMSE: 10.646254539489746 for 10\n",
      "AAPL MAE: 8.795839309692383 for 10\n",
      "AAPL MAPE: 5.053306743502617 for 10\n",
      "AAPL r2: 0.8675013780593872 for 10\n",
      "\n",
      "Best model is from checkpoint: ./20_pochs_patch_tsm_results_TWSE_pred_length_1/checkpoint-4480 with MSE: 0.0007\n",
      "(848, 1)\n",
      "TWSE RMSE: 405.82415771484375 for 1\n",
      "TWSE MAE: 312.3268127441406 for 1\n",
      "TWSE MAPE: 1.7796481028199196 for 1\n",
      "TWSE r2: 0.9794740080833435 for 1\n",
      "\n",
      "Best model is from checkpoint: ./20_pochs_patch_tsm_results_TWSE_pred_length_5/checkpoint-4480 with MSE: 0.0011\n",
      "(4220, 1)\n",
      "TWSE RMSE: 518.2621459960938 for 5\n",
      "TWSE MAE: 404.9559020996094 for 5\n",
      "TWSE MAPE: 2.305012196302414 for 5\n",
      "TWSE r2: 0.9663770794868469 for 5\n",
      "\n",
      "Best model is from checkpoint: ./20_pochs_patch_tsm_results_TWSE_pred_length_10/checkpoint-4480 with MSE: 0.0016\n",
      "(8390, 1)\n",
      "TWSE RMSE: 615.4713134765625 for 10\n",
      "TWSE MAE: 481.1973571777344 for 10\n",
      "TWSE MAPE: 2.742215059697628 for 10\n",
      "TWSE r2: 0.9523884654045105 for 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from transformers import PatchTSMixerForPrediction\n",
    "import os\n",
    "import torch\n",
    "from transformers import PatchTSMixerForPrediction\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "for name in dfs:\n",
    "    for pred_length in [1, 5, 10]:\n",
    "        (X_train, y_train), (X_val, y_val), (X_test, y_test), scaler = get_data_for_period(dfs[name], window_size, pred_length)\n",
    "        train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "        valid_dataset = TimeSeriesDataset(X_val, y_val)\n",
    "        test_dataset  = TimeSeriesDataset(X_test, y_test)\n",
    "\n",
    "        results_folder = f\"./20_pochs_patch_tsm_results_{name}_pred_length_{pred_length}\"\n",
    "\n",
    "        checkpoint_dirs = [os.path.join(results_folder, d) for d in os.listdir(results_folder) if d.startswith(\"checkpoint-\")]\n",
    "\n",
    "        best_checkpoint = None\n",
    "        best_score = float(\"inf\")\n",
    "        \n",
    "        val_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "        for checkpoint_path in checkpoint_dirs:\n",
    "            model = PatchTSMixerForPrediction.from_pretrained(checkpoint_path)\n",
    "            model.eval()\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "\n",
    "            for batch in val_loader:\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**batch) \n",
    "                all_preds.append(outputs.prediction_outputs.flatten())\n",
    "                all_labels.append(batch[\"future_values\"].numpy().flatten())\n",
    "\n",
    "\n",
    "            all_preds = np.concatenate(all_preds, axis=0)\n",
    "            all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "            score = mean_squared_error(all_labels, all_preds)\n",
    "\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_checkpoint = checkpoint_path\n",
    "\n",
    "        print(f\"\\nBest model is from checkpoint: {best_checkpoint} with MSE: {best_score:.4f}\")\n",
    "\n",
    "        best_model = PatchTSMixerForPrediction.from_pretrained(best_checkpoint)\n",
    "\n",
    "\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for batch in test_loader:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)  \n",
    "            all_preds.append(outputs.prediction_outputs.flatten())\n",
    "            all_labels.append(batch[\"future_values\"].numpy().flatten())\n",
    "\n",
    "\n",
    "        all_preds = np.concatenate(all_preds, axis=0).reshape(-1, 1)\n",
    "        all_labels = np.concatenate(all_labels, axis=0).reshape(-1, 1)\n",
    "        \n",
    "        print(all_preds.shape)\n",
    "\n",
    "        preds_flat = scaler.inverse_transform(all_preds)\n",
    "        labels_flat = scaler.inverse_transform(all_labels)\n",
    "\n",
    "        mse  = mean_squared_error(labels_flat, preds_flat)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae  = mean_absolute_error(labels_flat, preds_flat)\n",
    "\n",
    "        mask = labels_flat != 0\n",
    "        mape = (np.mean(np.abs((labels_flat[mask] - preds_flat[mask]) / labels_flat[mask])) * 100\n",
    "                if np.any(mask) else float('inf'))\n",
    "        r2   = r2_score(labels_flat, preds_flat)\n",
    "\n",
    "        \n",
    "        print(f\"{name} RMSE: {rmse} for {pred_length}\")\n",
    "        print(f\"{name} MAE: {mae} for {pred_length}\")\n",
    "        print(f\"{name} MAPE: {mape} for {pred_length}\")\n",
    "        print(f\"{name} r2: {r2} for {pred_length}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
